{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasumaha/Genai_notes/blob/main/20_LCEL_configurable_fields.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn5LUrFqVu4b"
      },
      "outputs": [],
      "source": [
        "%pip install langchain langchain_openai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHiKw5HpVu4e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"API_KEY_HERE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHOhWtsaVu4e"
      },
      "source": [
        "Oftentimes you may want to experiment with, or even expose to the end user, multiple different ways of doing things. In order to make this experience as easy as possible, we have defined two methods.\n",
        "\n",
        "First, a `configurable_fields` method. This lets you configure particular fields of a runnable.\n",
        "\n",
        "Second, a `configurable_alternatives` method. With this method, you can list out alternatives for any particular runnable that can be set during runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkGckwGGVu4f"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(temperature=0).configurable_fields(\n",
        "    temperature=ConfigurableField(\n",
        "        id=\"llm_temperature\",\n",
        "        name=\"LLM Temperature\",\n",
        "        description=\"The temperature of the LLM\",\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iV5y9I1ZVu4g",
        "outputId": "999fd831-0ffd-4452-e209-cd51352eddcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='17', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 11, 'total_tokens': 12}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-17f337c4-93b6-406d-b78d-9ee2c188b73f-0')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.invoke(\"pick a random number\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4lgYQ99Vu4g",
        "outputId": "6e614457-eacd-4697-c362-32358d503d58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='27', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 11, 'total_tokens': 12}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-053d586e-f1d0-4d80-9f91-115bbe7e60a4-0')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.with_config(configurable={\"llm_temperature\": 0.9}).invoke(\"pick a random number\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TilTEuByVu4g"
      },
      "source": [
        "## Configuring Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPlXKENRVu4h"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0)\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"Tell me a joke about {topic}\"\n",
        ").configurable_alternatives(\n",
        "    # This gives this field an id\n",
        "    # When configuring the end runnable, we can then use this id to configure this field\n",
        "    ConfigurableField(id=\"prompt\"),\n",
        "    # This sets a default_key.\n",
        "    # If we specify this key, the default LLM (ChatAnthropic initialized above) will be used\n",
        "    default_key=\"joke\",\n",
        "    # This adds a new option, with name `poem`\n",
        "    poem=PromptTemplate.from_template(\"Write a short poem about {topic}\"),\n",
        "    # You can add more configuration options here\n",
        ")\n",
        "chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSBN76GtVu4h",
        "outputId": "53713b36-9fa8-4f15-f729-a065b236a5f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the relationship any longer!\", response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 13, 'total_tokens': 34}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-eb2be3f4-df43-437f-8dc7-94053170ab30-0')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# By default it will write a joke\n",
        "chain.invoke({\"topic\": \"bears\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ehcL7VHVu4h",
        "outputId": "acff4b1e-5f66-44f1-bbe3-27e9c2acd312"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"In the forest deep and wide,\\nWhere the shadows dance and hide,\\nThere roams a creature strong and grand,\\nWith fur as dark as midnight's hand.\\n\\nThe bear, with paws like mighty claws,\\nStands tall and proud, without a pause,\\nIn search of food and shelter warm,\\nIn the wild, where it was born.\\n\\nWith a growl that shakes the earth,\\nAnd eyes that hold both fear and mirth,\\nThe bear is a symbol of strength and might,\\nA guardian of the day and night.\\n\\nSo let us respect this noble beast,\\nAnd in its presence, be at peace,\\nFor in the wild, where it roams free,\\nThe bear is a wonder to see.\", response_metadata={'token_usage': {'completion_tokens': 142, 'prompt_tokens': 13, 'total_tokens': 155}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-48a7d22d-047b-4d56-8531-b297c70c87b6-0')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We can configure it write a poem\n",
        "chain.with_config(configurable={\"prompt\": \"poem\"}).invoke({\"topic\": \"bears\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-4BFRa5Vu4h"
      },
      "source": [
        "## Saving Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKyx_gp3Vu4i",
        "outputId": "5a4b25f8-f91e-4287-cee5-6d30cd6c190e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"name\": null, \"bound\": {\"name\": null, \"first\": {\"name\": null, \"default\": {\"name\": null, \"input_variables\": [\"topic\"], \"input_types\": {}, \"output_parser\": null, \"partial_variables\": {}, \"metadata\": null, \"tags\": null, \"template\": \"Tell me a joke about {topic}\", \"template_format\": \"f-string\", \"validate_template\": false, \"_type\": \"prompt\"}, \"config\": null, \"which\": [\"prompt\", null, null, null, false], \"alternatives\": {\"poem\": {\"name\": null, \"input_variables\": [\"topic\"], \"input_types\": {}, \"output_parser\": null, \"partial_variables\": {}, \"metadata\": null, \"tags\": null, \"template\": \"Write a short poem about {topic}\", \"template_format\": \"f-string\", \"validate_template\": false, \"_type\": \"prompt\"}}, \"default_key\": \"joke\", \"prefix_keys\": false}, \"middle\": [], \"last\": {\"model_name\": \"gpt-3.5-turbo\", \"model\": \"gpt-3.5-turbo\", \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"_type\": \"openai-chat\"}}, \"kwargs\": {}, \"config\": {\"configurable\": {\"llm\": \"openai\"}}, \"config_factories\": [], \"custom_input_type\": null, \"custom_output_type\": null}'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai_joke = chain.with_config(configurable={\"llm\": \"openai\"})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}